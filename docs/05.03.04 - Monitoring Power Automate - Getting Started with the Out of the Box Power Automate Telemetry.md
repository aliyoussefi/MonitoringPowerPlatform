# Monitoring the Power Platform: Power Automate - Getting Started with the Out of the Box Power Automate Telemetry

## Summary

**[Microsoft Power Automate](https://docs.microsoft.com/en-us/power-automate/getting-started)** is a service allowing makers to create business processes, orchestrations and workflows to help achieve common and even complex business requirements. Within the Power Platform, Power Automate represents one of the most important pillars of the platform. It provides a no to low code solution to process automation. From sending **[push notifications to mobile devices](https://docs.microsoft.com/en-us/powerapps/maker/canvas-apps/add-notifications)**, to complex **[robotic process automation](https://flow.microsoft.com/en-us/ui-flows/)** flows, Power Automate can be used in virtually any workload.

The goal of this article is to assist in understanding and getting started with the Power Automate telemetry delivered natively from the Power Platform. We will provide a brief overview of why this is needed. Next, we will go into recommended Azure resource procurement and Power Platform setup and what to immediately expect. After that, we will look deeper into the insights and capabilities provided to us with this feature. Finally, we will briefly touch on how to correlate to existing Dataverse telemetry.

## Why should I enable the out of the box Power Automate telemetry?
### Fully Supported
In the past, organizations were limited to community (such as this one or the Center of Excellence) tools and recommendations to monitor their Power Automate runs. Solutions including additional connectors to Azure Log Analytics or Azure Application Insights helped bridge this gap. These solutions still serve a valuable purpose allowing organizations to enrich the data points delivered from the out of the box.

With the out of the box functionality to export telemetry directly to an organization's Azure Application Insights resource, Microsoft is providing a supported solution (once in GA).

### No Gaps in telemetry
With previous approaches, we relied on designers to implement a run time monitoring strategy or for organizations to continuously monitor for previous Power Automate runs. These approaches work but could be argued that gaps may happen. With the out of the box telemetry, we can ensure coverage for an entire environment's Power Automate flows.

### Guaranteed and Speedy Delivery
With community tools, we have seen retroactive or scrub processes that must run continuously. They require authentication that could be faulty. With the out of the box feature, Microsoft takes that workload off organizations' shoulders. The single point of failure in the design is now removed.

## Power Automate Monitoring Tools
### Power Automate Analytics in the Power Platform Admin Center

The **Power Automate Analytics** feature in the **Power Platform Admin Center** allows administrators to run reports for insights into flow usage, errors and the various connectors and flows their organization are creating.

**<u>The data in these reports is refreshed about every 3 hours and is retained for 28 days</u>**. To find the last refresh date, look in the upper right hand corner of the Analytics window.

<img src="https://raw.githubusercontent.com/aliyoussefi/MonitoringPowerPlatform/main/Artifacts/PowerAutomateAnalytics/LastRefreshTime.JPG"  />

#### Who can access this data?

As shown in [this article](https://docs.microsoft.com/en-us/power-platform/admin/analytics-flow#who-can-view-these-reports) there consist of various admin roles within Office 365 that will scope to specific reports. **Environment Admin will scope to environments the admin has access to** while other admin roles will expose every environment.

### Power Automate Analytics in the Tenant Level Analytics / Center of Excellence

Power Platform administrators have the ability to export usage data to an Azure Storage account using a fully supported data export. This is useful for tools such as The Power Platform Center of Excellence that can build robust reports for displaying data points from this export. This also allows organizations the ability to go deeper into usage using their own preferred toolkit. Business units within the organization can slice and dice data important to them using pre-defined models. Similar to the Power Automate Analytics, but flexible enough to avoid permission sprawl, data analysts can decide how they want to aggregate and explore.

Specifically to Power Automate, this helps track who is building what and how often the flows are used. It does come with some caveats. Usage analytics are available at specific intervals like the Power Automate Analytics. For platform support teams this can prove challenging to work with. This level of insight doesn't go to the run level leaving engineers to go to the flow history which can be extensive based on usage.

### Power Automate Telemetry Data Export




## Choosing between Log Analytics and Application Insights

The information above has provided mechanisms showing how to deliver events to **Azure Monitor utilizing the Azure Log Analytics Data Collector or the Azure Application Insights REST API**. Choosing one of the other requires considerations into the features and benefits and maybe more importantly the limitations of both. For an overview of each please review the [Monitoring the Power Platform: Introduction and Index](https://community.dynamics.com/crm/b/crminthefield/posts/monitoring-the-power-platform-introduction) article.

<img src="https://raw.githubusercontent.com/aliyoussefi/MonitoringPowerPlatform/main/Artifacts/PowerAutomate/LogAnalytics/workspaces.png"  />

As we progress through the **Monitoring the Power Platform series**, we will dive deeper into these considerations and why to choose one over the other based on requirements. Ultimately the log store for **Azure Application Insights** is available in **Azure Log Analytics** but the features provided by **Azure Application Insights** allow for deep "insights" into scenarios we are interested in.

## Next Steps

In this article we have discussed **using custom identifiers to help track flow history and specifically group parent and child flows together**. We have examined how we can **use trigger conditions to enforce the use of custom identifiers**. From there we reviewed the **Azure Log Analytics Data Collector** connector and how to setup and send messages to custom tables. After that, we went into building and sending **Azure Application Insights** messages directly in **Power Automate flow**.

In previous articles, [we discussed how to **evaluate workflows, triggers and run functions to help deliver insights**](https://community.dynamics.com/crm/b/crminthefield/posts/monitoring-the-power-platform-power-automate---run-time-part-1-triggers-workflows-and-actions). In the following articles covering **Microsoft Power Automate Flow** run time, we will discuss **pushing events to Application Insights and reviewing previous flow runs for monitoring and governance**.

If you are interested in learning more about [**specialized guidance and training** for monitoring or other areas of the Power Platform](https://community.dynamics.com/crm/b/crminthefield/posts/pfe-dynamics-365-service-offerings), which includes a [monitoring workshop](https://community.dynamics.com/crm/b/crminthefield/posts/pfe-dynamics-365-service-offerings), please contact your **Microsoft representative** for further details. 

Your feedback is **<u>extremely valuable</u>** so please leave a comment below and I'll be happy to help where I can! Also, if you find any inconsistencies, omissions or have suggestions, [please go here to submit a new issue](https://github.com/aliyoussefi/MonitoringPowerPlatform/issues).

## Index

[Monitoring the Power Platform: Introduction and Index](https://community.dynamics.com/crm/b/crminthefield/posts/monitoring-the-power-platform-introduction)