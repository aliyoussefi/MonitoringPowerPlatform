# Continuous Monitoring: Monitoring Dynamics 365

*"You can see a lot just by observing" - Yogi Berra*

## Summary

The idea of monitoring Dynamics 365 or Model Driven Applications is not a new concept. Understanding where services are failing, users are running into errors, where form and business processes could be tuned for performance are key drivers for most if not all businesses, from small companies to enterprises. Luckily, the Dynamics 365 platform provides many tools to help audit and monitor business and operational events.

This article will cover locating and downloading environment analytics using the Common Data Service for Analytics. Questions regarding capacity and all up usage can be answered here. For specific operational events the Office 365 Service and Compliance Center will be explored for both manual and automated gathering. For specific activities or workloads within the platform we will explore tools to capture performance markers as well as delivering custom messages to Azure Application Insights. Finally we will examine how to work to better understand API throttles.

## Audits and Activity Data

Auditing allows administrators the ability to track changes to Dynamics 365 data and user interactions with the system. This article isn't meant to cover how auditing works or everything that auditing provides, I did want to point out common concerns I've seen. In this section we will cover the Unified Audit Log and Common Data Service for Analytics specifically. Be aware there are other ways to audit in Dynamics, a good starting point if you're not familiar or want a handy reference is here: [Auditing overview](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/auditing-overview). To configure auditing, please refer to this article: [Configure entities and attributes for auditing](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/configure-entities-attributes-auditing)

### Unified Audit Log

Starting with Dynamics 365, the capability to perform comprehensive logging for the Power Platform including Dynamics 365, Canvas Apps, Power Automate and Power BI. Some of the activities tracked are admin events such as provisioning instances and publushing customizations. User activities include viewing grids or multiple records (e.g. export to excel), CRUD operations, reading reports, etc. The list as the feature indicates is very comprehensive and can highlight specific actions taken by specific users at specific times. There are licensing requirements and Dynamics 365 organization requirements to be aware of before this can be enabled. For additional references on the requirements, please see the reference link below.

Reference: https://docs.microsoft.com/en-us/power-platform/admin/enable-use-comprehensive-auditing

To view this data there are two popular mechanisms, one is a way to track manually while the other provides a programmatic approach. The Office 365 Security and Compliance Portal allows admins to review the activity logs and export data. This portal is helpful to understand what activities can be searched and extracted programmatically with the API or PowerShell tooling.

#### Office 365 Security and Compliance Portal

This reference includes information about all of the services audited with the security and compliance center and how long the expected latency is for each.

[Search the audit log in the Security & Compliance Center](https://docs.microsoft.com/en-us/microsoft-365/compliance/search-the-audit-log-in-security-and-compliance?view=o365-worldwide)

#### Office 365 Management Activity API Reference

The Office 365 Management Activity API is a RESTful API allowing for a search of the audit log for monitoring and analytical purposes. The API allows developers to start and stop subscriptions to events and to retrieve content scoped to a particular service. Once configured the subscription will notify interested parties on activities allowing for these activities to be pushed to your monitoring platform.

To get started you'll need to authenticate with Azure AD using OAuth2. Here's a reference to the instructions to set this up: [Get started with Office 365 Management APIs](https://docs.microsoft.com/en-us/office/office-365-management-api/get-started-with-office-365-management-apis)

A reference to both how to connect and request data as well as schema definitions are found below.

[Office 365 Management Activity API reference](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-reference)

[Office 365 Management Activity API schema](https://docs.microsoft.com/en-us/office/office-365-management-api/office-365-management-activity-api-schema)

#### Office 365 PowerShell usage

The Exchange Online PowerShell v2 Module contains a cmdlet called "Search-UnifiedAuditLog" that can help search Office 365 audit and activity data. 

[Search-UnifiedAuditLog](https://docs.microsoft.com/en-us/powershell/module/exchange/policy-and-compliance-audit/search-unifiedauditlog?view=exchange-ps)

The schema reference for the Activity API above will be helpful for searching for Dynamics, Power Apps, or Power Automate activities.

### Organization Insights / CDS for Analytics

A Common Data Service specific feature is the former Organization Insights or now called the Common Data Service for Analytics or CDS-A. 

https://docs.microsoft.com/en-us/power-platform/admin/analytics-common-data-service

https://docs.microsoft.com/en-us/power-platform-release-plan/2020wave1/power-platform-governance-administration/powershell-cmdlets-power-automate-admins-are-generally



## Collecting Client and Server Events

Before we discuss techniques on how to capture events in Dynamics 365 let's examine some meaningful events. From the client perspective this may include performance counters and metrics, user click events and navigation as well as geolocations and preferences of users. For server events collecting information from individual executions of business logic will prove helpful for troubleshooting and optimizing. Data from the execution context can be extracted to help correlate with external systems and integrations and exceptions can be centralized to allow for investigation and analysis.

Some features of the platform allow for collecting markers while other events we will have to supplement with custom delivery mechanisms. The next section of this article will detail the various tools that can be leveraged to collect metrics and logs for the Dynamics 365 platform.

## Performance Center

The Performance Center in Dynamics is a tool that can help analyze interactions with the platform such as opening a view, opening a form, saving a record, etc. The tool captures these events as well as external calls to other systems, web resources, images, that are requested by the form viewed by the user. These events are stacked in a timeline styled approach allowing us to see the chronological call stack.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/Capture.JPG)

In the image above we see the recent work blocks which represent events collected by the performance center. Each work block includes events and key performance indicators (KPI) that can be extracted and examined. Also key to point out is that the performance center can span across user actions including navigating forms, views, etc. and each work block can be pinned.

The following image shows the EditForm, SaveForm and Dialog page events. These represent the form load (EditForm), the save event (SaveForm) and the opening of a modal dialog (Dialog page).

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-DialogForm-Overview.JPG)

Clicking into a work block will populate the timeline area in the window. Each row is called a Zone which is a collection of specific events such as BrowserResourceTimings, WebService calls, etc.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-DialogForm-Overview.JPG)

In the following example, three work blocks that include Key Performance Indicators, are pinned and examined. The **BrowserResourceTimings** zone is expanded upon to determine additional or long running events.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/PerfCenter-ViewMarkers-CompareBrowserResourceTimings.gif)

### Key Performance Indicators and Metadata

Each work block contains timeline events, metadata, tags and key performance indicators. For the most part the metadata and KPI nodes contain relevant information when reviewing performance of a specific work block. The metadata will include the user agent, what version of the client and server and estimated latency. Also included are session and activity identifiers as well as other markers which are helpful when troubleshooting.

<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/PerfCenter-SaveForm-Metadata_and_KPI.JPG" style="zoom:50%;" />

The KPI node includes the name and duration of the event in the work block. In the image above we see the *SaveForm* event took 812 milliseconds.

In the image below we see the timeline window within the Performance Center showing the KPI flags. Clicking on the flag at the top of the window will populate the event window in the bottom right of the Performance Center for analysis.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-SaveForm-Timeline-KPI-AllRibbonsInit.JPG)

Within this event for AllRibbonsInitialized we see values specific to the KPI such as *LoadQuality*, *NumberOfRibbons* and *CleanLoad* among others. These markers can help us better understand if any caching took place, if this ribbon was initially loaded with this event and the cleanliness of the form load.

#### Attribution

Idle Tasks

### Timeline Events

Timeline events represent the flow of the work block captured and ca

#### How to turn on the Performance Center

These metrics can be retrieved by adding the *perf=true* query string parameter to the Dynamics 365 URL:

```
https://<your org>.crm.dynamics.com/main.aspx?perf=true
```

Also depending on the browser there exists a keystroke combination but I would recommend using the query string parameter where applicable. The keystroke combination for Microsoft Edge and Google Chrome is *Alt+Shift+Q*.

#### Collecting information from the Performance Center

The Performance Center includes the ability to export the data points collected in both json and csv formats. When clicked a new tab will appear with data points from the work block selected. This is key to call out to ensure you are collecting from the specific event (i.e. SaveForm) of interest.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/PerfCenter-ViewMarkers.gif)

Extracting the markers is helpful when you may not know exactly what you're looking for and need additional time to evaluate what exactly is going on. The KPI section will show the marker name and time during the user action it happened but to find out more an analysis of the timeline events is required. 

Consider the scenario of a user logging into the system and opening a lead form for the first time. When performing this action the form and data have not had a chance to be cached or stored locally which results in all items needed to be downloaded. This is sometimes referenced as a cold load. Reviewing the timeline event "**FullLoad**" we can determine what type of load the form rendered as.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-FormLoad-ColdLoad-JSON.JPG)

Now, once captured, the user opens the fly out window to choose another lead record but using the same form. Again using the "**FullLoad**" KPI timeline event we can see the *LoadType* is now two.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-FormLoad-WarmLoad-JSON.JPG)

Finally, imagine the user needs to navigate back to the original lead record opened on the same form. We can see now the *LoadType* is now three.

![](https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-FormLoad-HotLoad-JSON.JPG)

Comparing the cold load versus the cached form and data load:

<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/D365-Compare-ColdLoad-WarmLoad-KPI.JPG" style="zoom:70%;" />

## Adding Application Insights to Dynamics 365

### Client / User Interface

Adding the Application Insights JavaScript SDK to serve messages from the Dynamics 365 client is a fairly simple approach. A code snippet is available that downloads the SDK from a content delivery network which can then be cached for reuse. The steps to add it are located in a helpful reference here. There is also a very helpful tool part of the XrmToolbox located here. This snippet can be added to a web resource directly for when needed or added as its own helper library and included with other helpers such as jQuery.

When working with the snippet I've seen a couple of approaches that rename the global window object to something specific that will not conflict with internal mechanisms made to deliver telemetry for the platform. This follows a similar thought process used in web resources when implementing namespaces for our libraries.

Establishing the TelemetryClient is as easy as setting the instrumentation key. Once set, the SDK can be used and event traffic will be funneled to your Azure Application Insights store. 

[Application Insights JavaScript SDK GitHub](https://github.com/microsoft/ApplicationInsights-JS)

Mentioning adding Application Insights to your custom web resources, there is a react plugin that can be incorporated to track router and component changes and usage.

[React Plugin](https://github.com/microsoft/ApplicationInsights-JS/tree/master/extensions/applicationinsights-react-js)



<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/AppInsights-XrmTooling-CrmServiceClient-Kusto.JPG" style="zoom:70%;" />

### Server

Business logic can be introduced into Dynamics 365 events by using a plug-in. Plug-ins are a common customization technique that run in an isolated sandbox mode and as such have certain limitations in regards to interoperability. This article's focus is on monitoring so I won't get into how to write plug-ins or why sandbox isolation is preferred mode when registering plug-ins. For further reference please review these articles:

[Use plug-ins to extend business processes](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/plug-ins)

[Register a plug-in](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/register-plug-in)

[Access external web services](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/access-web-services)

When presented with questions regarding monitoring plug-ins I find two common themes: understanding errors in the code and investigating performance. Working with errors is a straight forward process as we need to handle the exception, report the exception and respond with a friendly message describing what's happened to our users. Typical questions that are asked from the performance perspective may include:

* How long did my plugin take to run? 
* If I'm making a call to an external API how I can determine if there is an issue with my integration? 
* Has the integration impacted expected performance? 
* How can log server side events without impacting my organization's database size?

#### Logging within Plugins and the ITracingService

The [ITracingService](https://docs.microsoft.com/en-us/dotnet/api/microsoft.xrm.sdk.itracingservice) interface assists developers by recording run-time custom information as an aid in diagnosing the cause of code failures or unexpected behavior in plug-ins. Before writing to the tracing service, you must first extract the tracing service object from the passed execution context. Afterwards, simply add [Trace](https://docs.microsoft.com/en-us/dotnet/api/microsoft.xrm.sdk.itracingservice.trace) calls to your custom code where appropriate passing any relevant diagnostic information in that method call. Once this is done the plugin is properly setup to deliver logs to the platform via an exception message sent back using the InvalidPluginExecutionException or through use of the Plugin Trace Log entity. To use the Plugin Trace Log entity, trace logging will have to be enabled by an administrator. The details to do this are [here](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/logging-tracing#enable-trace-logging). Its important to point out this caution from the referenced article:

"*While this job can be disabled or the frequency in which it occurs can be adjusted, failure to set it back to the original setting is frequently discovered to be the cause of performance issues later on.*" - [Additional information about the tracing service](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/logging-tracing#additional-information-about-the-tracing-service)

Additional Reference: [Use ITracingService in Plug-ins](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/best-practices/business-logic/use-itracingservice-plugins)

#### Logging within Plugins and Application Insights

As I hinted at before, there are limitations on what we can do within a plugin. As you may have guessed by now, incorporating Azure Application Insights is not as simple as dropping in a reference to an SDK like client side scripting. At this time only partial trust assemblies are allowed in a sandbox environment. Also, when registering your plugin assembly you'll be presenting with the issue of bringing along resources you rely on, such as the SDK.

The approach I've taken to account for this is to eliminate the need for the dependency on the SDK. Like the Vikings, we will navigate without a compass to guide us but rely on out keen observation skills and understanding of the Application Insights endpoint to help deliver what's needed! Luckily for us, the endpoint has been mapped out for us and we simply need to follow the guidelines set in front of us to accomplish our goal.



### SDK Tools and Client Applications

Recently I've been working with companies that have asked about monitoring running applications or compiled assemblies using the Dynamics or CDS SDK. I would highly recommend reading the article for [configuring tracing for XRM tooling](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/xrm-tooling/configure-tracing-xrm-tooling). The Xrm tooling objects are built upon the System.Diagnostics namespace which is a very powerful and quickly becoming one of my go to references. The System.Diagnostics.Tracing namespace in particular is useful as it allows events to be captured by Event Tracing for Windows (ETW). It's available for both the [.NET framework](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing?view=netframework-4.8) and [.NET core](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing?view=netcore-3.1).

For the Xrm tooling objects, tracing can be configured for the CrmServiceClient, the CrmConnectControl and the WebResourceUtility. Multiple listeners can be configured including text writers and event logging as mentioned in the article. What's not mentioned is that Azure Application Insights offers a listener which will allow us to seamlessly add delivery of trace events to Azure Application Insights...without touching the underlying code! This article describing using Application Insights with .NET will help describe how to set this up: [Explore .NET/.NET Core and Python trace logs in Application Insights](https://docs.microsoft.com/en-us/azure/azure-monitor/app/asp-net-trace-logs). As with other listeners you'll need to add the trace listener or shared listeners, the listener to the source and the configured switch. When configured the assemblies need to be added to the folder of the running application. 

<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/AppInsights-Client-Assemblies.JPG" style="zoom:70%;" />

Once complete, if needed, restart the running service to allow the changes to be picked up and then sit back and watch the  events begin to populate.

<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/AppInsights-XrmTooling-CrmServiceClient-Kusto.JPG" style="zoom:70%;" />



## Thoughts on API monitoring

https://docs.microsoft.com/en-us/power-platform/admin/api-request-limits-allocations

As mentioned in the Common Data Service for Analytics section, we can monitor API usage at a high level for trends. This tool provides useful visualizations to help discover platform usage. This can help determine business critical workloads which will grow in importance during our daily usage of the platform. Determining peak usage times and implementing proactive checks can help ensure our business continues as normal. To help with this, the Power Platform, specifically the Common Data Service has provided protective safe guards, known as service protection limits, for stability.

Some of the most common questions I've come across regarding the the Common Data Service API is how to better monitor working with the API within the service protection limitations that could potentially occur. Specific numbers or limits based on usage will not be discussed here but I want to take this opportunity to explore how to interpret API responses and opportunities to extract and track API interactions. For more information about Common Data Service protection limits please refer to this article: [Service Protection API Limits](https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/api-limits)

As mentioned in the article, the limits for this specific API are broadcast with what is called a HTTP header. HTTP headers can be used for passing details between connected systems such as instructions or usage information. Typical general headers include describing the content of the request, how to return the response and user information such as tokens or credentials. Below is an image of a simple bing request for "*common data service api limits*". Here you can see the *User-Agent*, *Accept*, *Accept-Encoding* and other headers:

<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/ApiLimits-Headers-Bing.JPG" style="zoom:70%;" />

Depending on how you're sending the request, you may or may not receive this header information back. Working with the XrmTooling objects the HTTP header isn't returned and this is by design. Reviewing the note in the Service Protection API Limits reference, this is the recommended tooling for client applications. If its required to not rely on SDK dependencies then use the Web API. When using the Web API from either an external source or from within Dynamics with a web resource the HTTP headers do populate.

<img src="https://raw.githubusercontent.com/wiki/aliyoussefi/D365-Monitoring/Artifacts/Dynamics/ApiLimits-Headers-D365-WebApi.JPG" />

#### What to do if throttled?

If throttled, a [Retry-After](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After) header will appear representing the value in seconds until another request can be made. If throttled review common architectural patterns referenced in the [Transient Fault Handling](https://docs.microsoft.com/en-us/azure/architecture/best-practices/transient-faults) best practices. The [Retry](https://docs.microsoft.com/en-us/azure/architecture/patterns/retry) Pattern mentioned in the Service Protection API Limits reference provides a code sample using the Retry-After response and waiting the appropriate amount of time. 



Another approach is the [Idempotent Retry](http://www.servicedesignpatterns.com/WebServiceInfrastructures/IdempotentRetry) pattern leveraging unique identifiers or the native Azure Service Bus integration to prevent duplicate requests. Using a message store we can 

## Next Steps

In this article we covered 